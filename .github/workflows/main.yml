name: Scrape live deals (every 3 hours)

on:
  schedule:
    - cron: "0 */3 * * *"       # every 3 hours at minute 0
  workflow_dispatch: {}         # allow manual runs

permissions:
  contents: write               # needed to push the JSON back

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      TEQUILA_API_KEY: ${{ secrets.TEQUILA_API_KEY }}
      AMADEUS_API_KEY: ${{ secrets.AMADEUS_API_KEY }}
      AMADEUS_API_SECRET: ${{ secrets.AMADEUS_API_SECRET }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper_bot/requirements.txt

      - name: Run scraper
        run: |
          python scraper_bot/scrape.py

      - name: Commit updated JSON
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git add data/live_deals.json
          git commit -m "Update live_deals.json [skip ci]" || { echo "No changes to commit"; exit 0; }

          # Use repo slug from context to avoid typos
          git remote set-url origin "https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git"
          git pull --rebase
          git push
